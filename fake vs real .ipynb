{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d607b59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revan\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e2642",
   "metadata": {},
   "source": [
    "train_gen = ImageDataGenerator(rescale =1./255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e9b7e9",
   "metadata": {},
   "source": [
    "path=r\"C:\\Users\\revan\\OneDrive\\Desktop\\COMPUTER VISION\\DATASET\\real_and_fake_face\\train\"\n",
    "training_set=train_gen.flow_from_directory(path,target_size=(64,64),batch_size=32,class_mode='binary')\n",
    "print(training_set.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c64f9f1",
   "metadata": {},
   "source": [
    "test_gen= ImageDataGenerator(rescale =1./255)\n",
    "path=r\"C:\\Users\\revan\\OneDrive\\Desktop\\COMPUTER VISION\\DATASET\\real_and_fake_face\\test\"\n",
    "test_set=test_gen.flow_from_directory(path,target_size=(64,64),batch_size=32,class_mode='binary')\n",
    "print(test_set.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63604ba5",
   "metadata": {},
   "source": [
    "cnn =tf.keras.models.Sequential()\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n",
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "cnn.fit(x=training_set,validation_data=test_set,epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29301522",
   "metadata": {},
   "source": [
    "from keras.preprocessing import image\n",
    "path=r\"C:\\Users\\revan\\OneDrive\\Desktop\\COMPUTER VISION\\6dfb5660c821203ebfc479951993a0a3.jpg\"\n",
    "\n",
    "test_image=image.load_img(path,target_size=(64,64))\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "result=cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0]==1:\n",
    "    prediction='real'\n",
    "else:\n",
    "    prediction='fake'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd536b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revan\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1433 images belonging to 2 classes.\n",
      "Found 608 images belonging to 2 classes.\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\revan\\anaconda3\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.5056 - loss: 2.5042 - val_accuracy: 0.5641 - val_loss: 1.2575\n",
      "Epoch 2/25\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.5764 - loss: 1.1586 - val_accuracy: 0.5954 - val_loss: 0.9616\n",
      "Epoch 3/25\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - accuracy: 0.5961 - loss: 0.9233 - val_accuracy: 0.5773 - val_loss: 0.8525\n",
      "Epoch 4/25\n",
      "\u001b[1m29/45\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.5576 - loss: 0.8578"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Data augmentation and rescaling for training set\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8,1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Directory path for training data\n",
    "train_path = r\"C:\\Users\\revan\\OneDrive\\Desktop\\COMPUTER VISION\\DATASET\\real_and_fake_face\\train\"\n",
    "training_set = train_gen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Data rescaling for test set\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_path = r\"C:\\Users\\revan\\OneDrive\\Desktop\\COMPUTER VISION\\DATASET\\real_and_fake_face\\test\"\n",
    "test_set = test_gen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Load the VGG16 model with pre-trained weights, excluding the top layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Freeze the layers in the base model to prevent them from being updated during training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the new model\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(training_set, validation_data=test_set, epochs=25)\n",
    "\n",
    "# Load and preprocess the test image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f44aa596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "{'fake': 0, 'real': 1}\n",
      "real\n"
     ]
    }
   ],
   "source": [
    "test_image_path = r\"C:\\Users\\revan\\OneDrive\\Desktop\\COMPUTER VISION\\pngtree-man-is-make-a-fake-face-picture-image_3184022.jpg\"\n",
    "test_image = image.load_img(test_image_path, target_size=(64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image = test_image / 255.0  # Rescale the image to match training set preprocessing\n",
    "\n",
    "# Predict the class of the test image\n",
    "result = model.predict(test_image)\n",
    "\n",
    "# Print the class indices\n",
    "print(training_set.class_indices)\n",
    "\n",
    "# Determine and print the prediction based on the result\n",
    "if result[0][0] > 0.5:\n",
    "    prediction = 'real'\n",
    "else:\n",
    "    prediction = 'fake'\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dafbf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "839f2433",
   "metadata": {},
   "source": [
    "# cv2.CascadeClassifier:\n",
    "\n",
    "This is a function in OpenCV used to load the Haar cascade model.\n",
    "cv2.data.haarcascades: This is the directory path where OpenCV stores its default Haar cascades for various objects (like faces, eyes, etc.).\n",
    "'haarcascade_frontalface_default.xml': This is the specific Haar cascade file used for detecting frontal faces. The file contains the trained model data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa5fad",
   "metadata": {},
   "source": [
    "# Output:\n",
    "\n",
    "faces: This variable contains a list of rectangles where each rectangle represents a detected face. \n",
    "Each rectangle is defined by the coordinates of its top-left corner (x, y) and its width w and height h.\n",
    "For example, if faces contains [(10, 20, 100, 100), (200, 150, 80, 80)], \n",
    "it means two faces were detected: one at coordinates (10, 20) with size 100x100, and \n",
    "    another at coordinates (200, 150) with size 80x80."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de5a870",
   "metadata": {},
   "source": [
    "In the context of machine learning and statistical modeling, the fit method is used to train or fit a model to the given data. Here’s a simple explanation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec368f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
